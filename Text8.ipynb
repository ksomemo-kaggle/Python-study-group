{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text8.ipynb のコピー","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kIjWCCyYw_c2","colab_type":"text"},"source":["#深層距離学習を実装してみよう"]},{"cell_type":"markdown","metadata":{"id":"Nhu8hMwLxHUl","colab_type":"text"},"source":["##前回の復習\n","+ CIFAR-10（カラー）を題材に、オートエンコーダを使って異常検知\n","+ 正常：猫、異常：犬にして学習\n","+ オートエンコーダではCIFAR-10に太刀打ちできなかった（異常検知できなかった）\n","\n","##今回の内容\n","+ 深層距離学習とは\n","+ 深層距離学習（L2-SoftmaxLoss）の論文説明\n","+ L2-SoftmaxLossをKerasで実装\n","+ Cifar-10を題材に「通常のCNN VS L2-SoftmaxLoss」の**分類精度**の比較\n"]},{"cell_type":"markdown","metadata":{"id":"5Wy30GnGySco","colab_type":"text"},"source":["##前回で多かった質問\n","「オートエンコーダ」は、なぜカラー画像に対応できないのか？  \n","（回答）\n","+ そもそも、元画像と再構成画像を比べて異常検知するのは限界がある。\n","+ この手法は、細かい異常は捉えにくい。さらに背景に依存して異常度が変化する。\n","+ CIFAR-10の場合、犬と猫の違いは細かい所に集中している可能性がある（鼻や口など）。\n","+ さらに、多様な背景があるため、そこの部分に引っ張られ異常検知しにくい。\n","+ カラーの場合、3チャンネル分あるので、これらの要素がより大きく効いてくる。\n","+ モノクロ画像であっても、細かい異常や背景が多様だと対応できない。\n","\n","（オートエンコーダの発展形）\n","+ 細かい異常を検知するために、小窓を用いる手法やSSIMという指標を用いる論文もある\n","+ https://qiita.com/shinmura0/items/811d01384e20bfd1e035\n","+ https://qiita.com/shinmura0/items/ee074172ec3c818b614e"]},{"cell_type":"markdown","metadata":{"id":"ys7BUksZvX7V","colab_type":"text"},"source":["#深層距離学習（Deep Metric Learning）とは\n","+ 元々は、分類問題で精度アップのために考えられた手法\n","+ 最近では、人物同定の際になくてはならない技術（それだけ人物同定の問題は難しい）\n","+ 似ているもの同士を近くに埋め込む手法\n","+ 上記の特性を生かし、異常画像は「似ていない」ため、外れた位置に埋め込まれ、異常検知可能となる"]},{"cell_type":"markdown","metadata":{"id":"Ls-1TyzQHyTW","colab_type":"text"},"source":["#L2-SoftmaxLossの論文\n","https://qiita.com/shinmura0/items/0d6685e378a57ca97a91"]},{"cell_type":"markdown","metadata":{"id":"nM8AuzWISNMF","colab_type":"text"},"source":["#L2-SoftmaxLossの実装\n","##data load"]},{"cell_type":"code","metadata":{"id":"vHDvvPChnBRC","colab_type":"code","outputId":"a120c604-c01d-42dd-aa08-41518f6ea10f","executionInfo":{"status":"ok","timestamp":1580700347661,"user_tz":-540,"elapsed":2691,"user":{"displayName":"shinmura shinmura","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDVNvIeOf7at5hGMYGVZ57WAAZy2cUySUGtMgQvHg=s64","userId":"02985854947085672136"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["from keras.datasets import cifar10\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras import backend as K\n","from keras.utils import to_categorical\n","from keras.applications import MobileNetV2\n","from keras.layers import Input, GlobalAveragePooling2D\n","from keras.layers import Dense, Activation\n","from keras.models import Model\n","import keras\n","from keras.optimizers import Adam\n","\n","def get_cifar_data():\n","    # dataset\n","    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","    x_train = x_train.astype('float32') / 255\n","    x_test = x_test.astype('float32') / 255\n","        \n","    return x_train, x_test, y_train, y_test"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Ds9h-pd1NAur","colab_type":"code","outputId":"c5faf3cb-b60b-42f1-a6c7-c7450d98b4a6","executionInfo":{"status":"ok","timestamp":1580700365271,"user_tz":-540,"elapsed":18837,"user":{"displayName":"shinmura shinmura","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDVNvIeOf7at5hGMYGVZ57WAAZy2cUySUGtMgQvHg=s64","userId":"02985854947085672136"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x_train, x_test, y_train, y_test = get_cifar_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 13s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xrk93o0kK4wo","colab_type":"text"},"source":["##CNN"]},{"cell_type":"code","metadata":{"id":"9yKlDmWXK7YJ","colab_type":"code","colab":{}},"source":["def get_L2(x, y, classes=10):\n","    print(\"L2-SoftmaxLoss\")\n","    mobile = MobileNetV2(include_top=False, input_shape=x.shape[1:], alpha=0.5,\n","                         weights=None)\n","    \n","    # L2層と全結合層を付ける\n","    c = GlobalAveragePooling2D()(mobile.input)\n","    c = keras.layers.Lambda(lambda xx: 15*(xx)/K.sqrt(K.sum(xx**2)))(c) # L2-SoftmaxLoss\n","    c = Dense(classes, activation='softmax')(c)\n","    model = Model(inputs=mobile.input,outputs=c)\n","\n","    #model.summary()\n","\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=Adam(lr=0.0001, amsgrad=True),\n","                  metrics=['accuracy'])\n","    \n","    return model\n","\n","def get_Normal(x, y, classes=10):\n","    print(\"Normal CNN\")\n","    mobile = MobileNetV2(include_top=False, input_shape=x.shape[1:], alpha=0.5,\n","                         weights=None)\n","    \n","    # 全結合層を付ける\n","    c = GlobalAveragePooling2D()(mobile.output)\n","    c = Dense(classes, activation='softmax')(c)\n","    model = Model(inputs=mobile.output,outputs=c)\n","\n","    #model.summary()\n","\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=Adam(lr=0.0001, amsgrad=True),\n","                  metrics=['accuracy'])\n","    \n","    return model\n","\n","def train(model, x, y, x_val, y_val):\n","    #学習\n","    Y = to_categorical(y)\n","    Y_val = to_categorical(y_val)\n","    hist = model.fit(x, Y,\n","                     validation_data=(x_val, Y_val),\n","                     batch_size=128, epochs=1000, verbose = False)\n","\n","    plt.figure()               \n","    plt.plot(hist.history['val_acc'],label=\"val_acc\")\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","    print(\"Validation Accuracy\",np.max(hist.history['val_acc']))\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yVPdxk0Qc1Xe","colab_type":"text"},"source":["##Normal CNN"]},{"cell_type":"code","metadata":{"id":"pqpICh5xc_7F","colab_type":"code","colab":{}},"source":["model = get_Normal(x_train, y_train)\n","model = train(model, x_train, y_train, x_test, y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UhVRizDLc7UF","colab_type":"text"},"source":["##L2-SoftmaxLoss"]},{"cell_type":"code","metadata":{"id":"Smi9FK_cdBwd","colab_type":"code","colab":{}},"source":["model = get_L2(x_train, y_train)\n","model = train(model, x_train, y_train, x_test, y_test)"],"execution_count":0,"outputs":[]}]}
